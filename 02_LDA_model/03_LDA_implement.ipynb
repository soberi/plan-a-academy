{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementation of LDA model\n",
    "\n",
    "### 1.1 Importing modules and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('pkl_cellar/df_stemmed.pkl', 'rb') as file:\n",
    "    data_stemmed = pickle.load(file)\n",
    "    \n",
    "data_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Vectorizing and applying LDA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doc term matrix\n",
    "\n",
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X = vect.fit_transform(data_stemmed.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to model\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, \n",
    "                                learning_method=\"batch\", \n",
    "                                max_iter=25, \n",
    "                                random_state=0) \n",
    "\n",
    "academy_content = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pkl_cellar/academy_vect.pkl', 'wb') as av:\n",
    "    pickle.dump(academy_content, av, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each topic (a row in the components_), sort the features (ascending) \n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "\n",
    "# Get the feature names from the vectorizer\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names, \n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "topic_names = [\"{:>2} \".format(i) + \" \".join(words) for i, words in enumerate(feature_names[sorting[:, :2]])] \n",
    "\n",
    "# two column bar chart:\n",
    "\n",
    "for col in [0, 1]: \n",
    "    start=col*5\n",
    "    end=(col+1)*5\n",
    "    ax[col].barh(np.arange(5), np.sum(academy_content, axis=0)[start:end])\n",
    "    ax[col].set_yticks(np.arange(5))\n",
    "    ax[col].set_yticklabels(topic_names[start:end], ha=\"left\", va=\"top\")\n",
    "    ax[col].invert_yaxis()\n",
    "    ax[col].set_xlim(0, 700)\n",
    "    yax = ax[col].get_yaxis()\n",
    "    yax.set_tick_params(pad=130)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Tracing back results to their source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which articles are associated wtih topic one (climate make), word = business\n",
    "\n",
    "business = np.argsort(academy_content[:, 1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in business[:5]:\n",
    "    # show url and text\n",
    "    print(data_stemmed.loc[i].url, data_stemmed.loc[i].content)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Top 5 articles for the word 'business' in the biggest topic group (Topic 1: climat make)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Putting it all together\n",
    "### 2.1 Creating function (to be used as part of Flask app)\n",
    "\n",
    "The function should take data cleaned for NLP and output the topic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: vectorize! fit! return!\n",
    "\n",
    "def lda_vect_transform(df):\n",
    "    \n",
    "    vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "    X = vect.fit_transform(df.content)\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\", max_iter=25, random_state=0) \n",
    "    content = lda.fit_transform(X)\n",
    "    \n",
    "    return content, lda, vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_content, model, vect = lda_vect_transform(data_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: sorting!\n",
    "\n",
    "def lda_sort(content, model, vect):\n",
    "    \n",
    "    sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "    feature_names = np.array(vect.get_feature_names())\n",
    "    \n",
    "    return sorting, feature_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting, feature_names = lda_sort(transformed_content, model, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: let's see topic categories\n",
    "\n",
    "def top_cat(sorting, feature_names):\n",
    "    return mglearn.tools.print_topics(topics=range(10), \n",
    "                               feature_names=feature_names, \n",
    "                               sorting=sorting, \n",
    "                               topics_per_chunk=5, \n",
    "                               n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: plotting topic categories\n",
    "\n",
    "def plot_cat(sorting, feature_names, transformed_content):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    topic_names = [\"{:>2} \".format(i) + \" \".join(words) for i, words in enumerate(feature_names[sorting[:, :2]])] \n",
    "\n",
    "    # two column bar chart:\n",
    "\n",
    "    for col in [0, 1]: \n",
    "        start=col*5\n",
    "        end=(col+1)*5\n",
    "        ax[col].barh(np.arange(5), np.sum(transformed_content, axis=0)[start:end])\n",
    "        ax[col].set_yticks(np.arange(5))\n",
    "        ax[col].set_yticklabels(topic_names[start:end], ha=\"left\", va=\"top\")\n",
    "        ax[col].invert_yaxis()\n",
    "        ax[col].set_xlim(0, 700)\n",
    "        yax = ax[col].get_yaxis()\n",
    "        yax.set_tick_params(pad=130)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Putting everything in one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_model(df):\n",
    "    transformed_content, model, vect = lda_vect_transform(df)\n",
    "    sorting, feature_names = lda_sort(transformed_content, model, vect)\n",
    "    \n",
    "    # visualisation of the data\n",
    "    top_cat(sorting, feature_names)\n",
    "    plot_cat(sorting, feature_names, transformed_content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "emiss         climat        water         lemur         climat        \n",
      "carbon        make          woman         music         human         \n",
      "ga            energi        make          one           speci         \n",
      "global        product       oil           time          ecosystem     \n",
      "year          use           product       year          natur         \n",
      "greenhous     busi          palm          get           also          \n",
      "industri      compani       way           good          life          \n",
      "fuel          new           tree          tell          tree          \n",
      "million       environment   develop       well          forest        \n",
      "atmospher     life          plan          work          one           \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "carbon        work          environment   emiss         climat        \n",
      "make          peopl         compani       compani       plan          \n",
      "footprint     design        begin         carbon        action        \n",
      "compani       commun        becom         scope         take          \n",
      "start         project       day           measur        make          \n",
      "reduc         like          like          busi          one           \n",
      "take          anim          earth         plan          need          \n",
      "creat         social        see           reduc         support       \n",
      "want          understand    get           report        planet        \n",
      "help          go            greenwash     monitor       peopl         \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda_model(data_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the topics that make up an article\n",
    "Reversing the LDA model proved to be a bit complex. After trying out a few things I found a good solution which is presented in the notebook *04_LDA_topic_distribution*. The following section is the attempt at a prediction model to find out which topics make up an unseen article. (i.e. converting unsupervised output to a supervised problem).\n",
    "\n",
    "Please note: Due to time constraints, this is purerly a test for functionality as EDA was not yet performed and there is still further data cleaning to be implemented. The results of the supervised model sub-sub-optmial.\n",
    "\n",
    "### 3.1 Subsetting data to articles that successfully converted users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../02_LDA_model/pkl_cellar/success_urls.pkl', 'rb') as file:\n",
    "    success_urls = pickle.load(file)\n",
    "    \n",
    "success_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = [success_urls.loc[14].content, success_urls.loc[644].content, success_urls.loc[3156].content, \n",
    "             success_urls.loc[16].content, success_urls.loc[209].content, success_urls.loc[3080].content, \n",
    "             success_urls.loc[700].content, success_urls.loc[171].content, success_urls.loc[273].content]\n",
    "test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using this [medium article](https://towardsdatascience.com/unsupervised-nlp-topic-models-as-a-supervised-learning-input-cf8ee9e5cf28) to use our unsupervised model's reults as a supervised model to get the topic distributions for each article.\n",
    "\n",
    "### 4.1 Unfortunately, even though I've already gone through data cleaning, I need to see which format (data type) is being used for the model, so I'll need to rerun the data cleaning according to this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    out = [[word for word in simple_preprocess(str(doc))\n",
    "            if word not in stop_words]\n",
    "            for doc in texts]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this list of lists of words is just the articles tokenized\n",
    "\n",
    "remove_stopwords(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to implement bi-grams in the initial data cleaning process\n",
    "# but I need to see the output datatype now\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams(remove_stopwords(test_text), bi_min=15, tri_min=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(df):\n",
    "\n",
    "    words = list((df.content))\n",
    "    words = remove_stopwords(words)\n",
    "    bigram_mod = bigrams(words)\n",
    "    bigram = [bigram_mod[article] for article in words]\n",
    "    id2word = gensim.corpora.Dictionary(bigram)\n",
    "    \n",
    "    # removes most common and rare words\n",
    "    # it's possible I need to get rid of this one\n",
    "    # id2word.filter_extremes(no_below=10, no_above=0.35)\n",
    "    \n",
    "    id2word.compactify()\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram]\n",
    "    \n",
    "    return corpus, id2word, bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corp, train_id2w, train_bigram = get_corpus(success_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "logging.basicConfig(filename='lda_model.log', format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    lda_train = gensim.models.ldamulticore.LdaMulticore(corpus=train_corp,\n",
    "                                                        num_topics=10,\n",
    "                                                        id2word=train_id2w,\n",
    "                                                        chunksize=100,\n",
    "                                                        #workers=7, # Num. Processing Cores - 1\n",
    "                                                        passes=50,\n",
    "                                                        eval_every=1,\n",
    "                                                        per_word_topics=True)\n",
    "    lda_train.save('lda_train.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_train.print_topics(20, num_words=15)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Now we move on to creating vectors that will be the basis of our training model. This is comprised of topic distributions for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(success_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_urls.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(success_urls)):\n",
    "    # min_probability = 0.0 will show distribution of all 10 topics\n",
    "    # I may change this depending on how the output looks and what we actually need\n",
    "    top_topics = lda_train.get_document_topics(train_corp[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
    "    # attaches index of article to vector, \n",
    "    # can also be done for previous attempt\n",
    "    topic_vec.extend([success_urls.index[i]]) \n",
    "    train_vecs.append(topic_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Time to train the actual model. This is still a test set, if this works I will train the model on the big dataset (complete academy) and test it on the succes_urls.\n",
    "\n",
    "For training we need an actual prediction, in this case it would be a success measure. We can use the goal completions, but I'll actually need to add it to the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_vecs)\n",
    "y = np.array(success_urls.target_g13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/5 of content are held out as validation data on each\n",
    "# fold, then f1 scores are averaged\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression, stochastic gradient descent with log loss\n",
    "# and stochastic gradient descent with modified huber loss\n",
    "cv_lr_f1, cv_lrsgd_f1, cv_svcsgd_f1,  = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.222 +- 0.030\n",
      "Logisitic Regression SGD Val f1: 0.323 +- 0.067\n",
      "SVM Huber Val f1: 0.419 +- 0.196\n"
     ]
    }
   ],
   "source": [
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "    \n",
    "    # Logisitic Regression (may need to balance weights\n",
    "    # depends on results)\n",
    "    lr = LogisticRegression(class_weight= 'balanced', \n",
    "                            solver='newton-cg', \n",
    "                            fit_intercept=True).fit(X_train_scale, y_train)\n",
    "    \n",
    "    # May need to change the average, macro is for unweighted mean\n",
    "    # CHECK all f1 scores\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    cv_lr_f1.append(f1_score(y_val, y_pred, average='macro'))\n",
    "    \n",
    "    # Logistic Regression SGD\n",
    "    sgd = (linear_model.SGDClassifier(max_iter=1000, \n",
    "                                      tol=1e-3,\n",
    "                                      loss='log', \n",
    "                                      class_weight='balanced')\n",
    "                       .fit(X_train_scale, y_train))\n",
    "    \n",
    "    y_pred = sgd.predict(X_val_scale)\n",
    "    cv_lrsgd_f1.append(f1_score(y_val, y_pred, average='micro'))\n",
    "    \n",
    "    # SGD Modified Huber\n",
    "    sgd_huber = (linear_model.SGDClassifier(max_iter=1000, \n",
    "                                           tol=1e-3, \n",
    "                                           alpha=20, \n",
    "                                           loss='log',\n",
    "                                           class_weight='balanced')\n",
    "                             .fit(X_train_scale, y_train))\n",
    "    \n",
    "    y_pred = sgd_huber.predict(X_val_scale)\n",
    "    cv_svcsgd_f1.append(f1_score(y_val, y_pred, average='micro'))\n",
    "\n",
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')\n",
    "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_f1):.3f} +- {np.std(cv_svcsgd_f1):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hahahahahah these are just awful, but it's possible I'm using the wrong models for the purposes of this project. Also possible that the data set is too small or I'm using the wrong settings. Will need to do some research on how best to approach this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
