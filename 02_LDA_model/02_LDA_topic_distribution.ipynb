{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the topic distribution for each article\n",
    "\n",
    "- Start with smaller success_urls df with goal13 completions\n",
    "- Run LDA on it\n",
    "- Get topic names printed\n",
    "- Get topic distributions per html element\n",
    "\n",
    "## 1. importing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../04_Data/success_g13_corpus.pkl', 'rb') as file:\n",
    "    success_corpus = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../04_Data/success_g13_id2word.pkl', 'rb') as file:\n",
    "    success_id2word = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../04_Data/success_g13_train_bigram.pkl', 'rb') as file:\n",
    "    success_bigram = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. running the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=success_corpus,\n",
    "                                           id2word=success_id2word,\n",
    "                                           num_topics=10,\n",
    "                                           random_state=42,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"find\" + 0.015*\"datum\" + 0.014*\"also\" + 0.013*\"begin\" + 0.012*\"look\" + 0.011*\"one\" + 0.010*\"solut\" + 0.010*\"everi\" + 0.010*\"new\" + 0.009*\"creatur\"'),\n",
       " (1,\n",
       "  '0.034*\"climat\" + 0.023*\"sloth\" + 0.021*\"hand\" + 0.021*\"individu\" + 0.019*\"bank\" + 0.017*\"would\" + 0.017*\"habitat\" + 0.016*\"group\" + 0.015*\"level\" + 0.014*\"want\"'),\n",
       " (2,\n",
       "  '0.032*\"emiss\" + 0.029*\"energi\" + 0.016*\"lca\" + 0.014*\"process\" + 0.013*\"life_cycl\" + 0.012*\"long\" + 0.012*\"product\" + 0.011*\"bitcoin\" + 0.011*\"blockchain\" + 0.010*\"scope\"'),\n",
       " (3,\n",
       "  '0.027*\"approach\" + 0.022*\"result\" + 0.020*\"act\" + 0.015*\"economi\" + 0.014*\"carbon_footprint\" + 0.013*\"drive\" + 0.013*\"transit\" + 0.012*\"effici\" + 0.012*\"associ\" + 0.012*\"stakehold\"'),\n",
       " (4,\n",
       "  '0.030*\"credit\" + 0.028*\"entir\" + 0.023*\"month\" + 0.021*\"away\" + 0.014*\"read\" + 0.013*\"oper\" + 0.013*\"repres\" + 0.012*\"live\" + 0.012*\"happen\" + 0.011*\"still\"'),\n",
       " (5,\n",
       "  '0.034*\"plastic\" + 0.032*\"posit\" + 0.023*\"man\" + 0.021*\"water\" + 0.019*\"planetwid\" + 0.017*\"increas\" + 0.016*\"woman\" + 0.015*\"consid\" + 0.010*\"site\" + 0.009*\"comput\"'),\n",
       " (6,\n",
       "  '0.026*\"bear\" + 0.023*\"polar\" + 0.019*\"pop\" + 0.016*\"europ\" + 0.016*\"reef\" + 0.016*\"coral\" + 0.015*\"panda\" + 0.015*\"averag\" + 0.015*\"tiger\" + 0.015*\"cockroach\"'),\n",
       " (7,\n",
       "  '0.049*\"go\" + 0.044*\"wast\" + 0.025*\"local\" + 0.020*\"lemur\" + 0.016*\"region\" + 0.015*\"team\" + 0.014*\"requir\" + 0.013*\"assess\" + 0.012*\"inspir\" + 0.009*\"adapt\"'),\n",
       " (8,\n",
       "  '0.023*\"alreadi\" + 0.022*\"earli\" + 0.022*\"ecolog\" + 0.020*\"fashion\" + 0.019*\"realiti\" + 0.018*\"top\" + 0.018*\"footprint\" + 0.014*\"august\" + 0.014*\"welcom\" + 0.014*\"dinosaur\"'),\n",
       " (9,\n",
       "  '0.028*\"sustain\" + 0.022*\"climat_chang\" + 0.018*\"plan\" + 0.015*\"compani\" + 0.015*\"day\" + 0.014*\"also\" + 0.012*\"busi\" + 0.011*\"environment\" + 0.011*\"chang\" + 0.011*\"make\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Topic titles and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../04_Data/success_g13.pkl', 'rb') as file:\n",
    "    success_g13 = pickle.load(file)\n",
    "    \n",
    "success_g13.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays the 10 topics and their top 10 words and weights\n",
    "\n",
    "model_topics = lda_model.show_topics(formatted=False)\n",
    "model_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_titles = []\n",
    "\n",
    "for i in model_topics:\n",
    "    index, word_list = i\n",
    "    word, prob = word_list[0]\n",
    "    word1, prob1 = word_list[1]\n",
    "    topic_title = f'{word}_{word1}'\n",
    "    topic_titles.append(topic_title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist = []\n",
    "\n",
    "for i in range(len(success_g13)):\n",
    "    top_topics = lda_model.get_document_topics(success_corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
    "    topic_vec.extend([success_g13.index[i]]) \n",
    "    topic_dist.append(topic_vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. One-hot encoding topics to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can probably be part of the for loop that creates topic_dist to avoid this code repetition\n",
    "\n",
    "top_0 = [topic[0] for topic in topic_dist]\n",
    "top_1 = [topic[1] for topic in topic_dist]\n",
    "top_2 = [topic[2] for topic in topic_dist]\n",
    "top_3 = [topic[3] for topic in topic_dist]\n",
    "top_4 = [topic[4] for topic in topic_dist]\n",
    "top_5 = [topic[5] for topic in topic_dist]\n",
    "top_6 = [topic[6] for topic in topic_dist]\n",
    "top_7 = [topic[7] for topic in topic_dist]\n",
    "top_8 = [topic[8] for topic in topic_dist]\n",
    "top_9 = [topic[9] for topic in topic_dist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_g13 = success_g13.assign(find_datum=top_0, climat_sloth=top_1, emiss_energi=top_2, \n",
    "                                   approach_result=top_3, credit_entir=top_4, plastic_posit=top_5, \n",
    "                                   bear_polar=top_6, go_wast=top_7, alreadi_earli=top_8, \n",
    "                                   sustain_climat_chang=top_9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_g13.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LDA model function\n",
    "Df goes in, df with topic distribution comes out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 setting up the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lda(lda_corpus, lda_id2word):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=lda_corpus,\n",
    "                                                id2word=lda_id2word,\n",
    "                                                num_topics=10,\n",
    "                                                random_state=42,\n",
    "                                                update_every=1,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                per_word_topics=True)\n",
    "    \n",
    "\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Getting the topic titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_titles(lda_model):\n",
    "    \n",
    "    model_topics = lda_model.show_topics(formatted=False)\n",
    "    \n",
    "    topic_titles = []\n",
    "    \n",
    "    for i in model_topics:\n",
    "        index, word_list = i\n",
    "        word, prob = word_list[0]\n",
    "        word1, prob1 = word_list[1]\n",
    "        topic_title = f'{word}_{word1}'\n",
    "        topic_titles.append(topic_title)\n",
    "    \n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Get topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_distribution(df, lda_model, corpus):\n",
    "    \n",
    "    topic_dist = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        top_topics = lda_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "        topic_vec = [top_topics[i][1] for i in range(10)]\n",
    "        topic_vec.extend([df.index[i]]) \n",
    "        topic_dist.append(topic_vec)\n",
    "        \n",
    "    return topic_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Add topic distributions to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_results(topic_titles, topic_dist, df):\n",
    "    \n",
    "    for i, value in enumerate(topic_titles):\n",
    "        topic_col = [topic[i] for topic in topic_dist]\n",
    "        df[value] = topic_col\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_results_to_df(corpus, id2word, df):\n",
    "    \n",
    "    lda_model = run_lda(corpus, id2word)\n",
    "    titles = topic_titles(lda_model)\n",
    "    top_dist = topic_distribution(df, lda_model, corpus)\n",
    "    df = get_lda_results(titles,top_dist, df)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using function on big full academy df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../04_Data/full_academy_corpus.pkl', 'rb') as file:\n",
    "    academy_corpus = pickle.load(file)\n",
    "\n",
    "with open('../04_Data/full_academy_id2word.pkl', 'rb') as file:\n",
    "    academy_id2word = pickle.load(file)\n",
    "\n",
    "with open('../04_Data/academy_posts.pkl', 'rb') as file:\n",
    "    academy_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>content</th>\n",
       "      <th>tag</th>\n",
       "      <th>human_one</th>\n",
       "      <th>seem_focu</th>\n",
       "      <th>less_decid</th>\n",
       "      <th>even_long</th>\n",
       "      <th>plan_sustain</th>\n",
       "      <th>cultur_nativ</th>\n",
       "      <th>bee_music</th>\n",
       "      <th>tree_natur</th>\n",
       "      <th>water_credit</th>\n",
       "      <th>year_understand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://plana.earth/academy/how-sustainable-is...</td>\n",
       "      <td>How sustainable is your office Christmas party?</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>Christmas is just around the corner! Unfortuna...</td>\n",
       "      <td>p</td>\n",
       "      <td>0.129480</td>\n",
       "      <td>0.064434</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.017146</td>\n",
       "      <td>0.038770</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>0.230422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://plana.earth/academy/how-sustainable-is...</td>\n",
       "      <td>How sustainable is your office Christmas party?</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>Before we start, here are a few statistics on ...</td>\n",
       "      <td>p</td>\n",
       "      <td>0.170685</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>0.046098</td>\n",
       "      <td>0.020283</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>0.255159</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>0.423192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://plana.earth/academy/how-sustainable-is...</td>\n",
       "      <td>How sustainable is your office Christmas party?</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>It is time for the office Christmas Party Quiz!</td>\n",
       "      <td>h2</td>\n",
       "      <td>0.201742</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>0.065292</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>0.293736</td>\n",
       "      <td>0.024476</td>\n",
       "      <td>0.288286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://plana.earth/academy/how-sustainable-is...</td>\n",
       "      <td>How sustainable is your office Christmas party?</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>Find out how sustainable your Christmas Party ...</td>\n",
       "      <td>p</td>\n",
       "      <td>0.193324</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.104568</td>\n",
       "      <td>0.027951</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.350031</td>\n",
       "      <td>0.023436</td>\n",
       "      <td>0.207561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://plana.earth/academy/how-sustainable-is...</td>\n",
       "      <td>How sustainable is your office Christmas party?</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>May the Merry Force be with you!</td>\n",
       "      <td>h2</td>\n",
       "      <td>0.269240</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.052097</td>\n",
       "      <td>0.071576</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.352234</td>\n",
       "      <td>0.026832</td>\n",
       "      <td>0.141477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://plana.earth/academy/how-joe-biden-u-s-...</td>\n",
       "      <td>How will Biden and the US rejoin the Paris Agr...</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>It is the fifth anniversary of the Paris Clima...</td>\n",
       "      <td>p</td>\n",
       "      <td>0.124986</td>\n",
       "      <td>0.013552</td>\n",
       "      <td>0.003545</td>\n",
       "      <td>0.029408</td>\n",
       "      <td>0.067596</td>\n",
       "      <td>0.018071</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>0.209292</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.504694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://plana.earth/academy/how-joe-biden-u-s-...</td>\n",
       "      <td>How will Biden and the US rejoin the Paris Agr...</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>The US President-Elect Joe Biden vows to rejoi...</td>\n",
       "      <td>p</td>\n",
       "      <td>0.122715</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.028964</td>\n",
       "      <td>0.039784</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.176903</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.568635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://plana.earth/academy/how-joe-biden-u-s-...</td>\n",
       "      <td>How will Biden and the US rejoin the Paris Agr...</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>This follows the United States’ withdrawal fro...</td>\n",
       "      <td>p</td>\n",
       "      <td>0.086032</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.146809</td>\n",
       "      <td>0.031940</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.154619</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.492831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://plana.earth/academy/how-joe-biden-u-s-...</td>\n",
       "      <td>How will Biden and the US rejoin the Paris Agr...</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>Today, the Trump Administration officially lef...</td>\n",
       "      <td>p</td>\n",
       "      <td>0.148504</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>0.037333</td>\n",
       "      <td>0.035093</td>\n",
       "      <td>0.048196</td>\n",
       "      <td>0.021547</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>0.217574</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.441196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://plana.earth/academy/how-joe-biden-u-s-...</td>\n",
       "      <td>How will Biden and the US rejoin the Paris Agr...</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>Today, the Trump Administration officially lef...</td>\n",
       "      <td>p</td>\n",
       "      <td>0.153953</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.038197</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.018685</td>\n",
       "      <td>0.420737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://plana.earth/academy/how-sustainable-is...   \n",
       "1  https://plana.earth/academy/how-sustainable-is...   \n",
       "2  https://plana.earth/academy/how-sustainable-is...   \n",
       "3  https://plana.earth/academy/how-sustainable-is...   \n",
       "4  https://plana.earth/academy/how-sustainable-is...   \n",
       "5  https://plana.earth/academy/how-joe-biden-u-s-...   \n",
       "6  https://plana.earth/academy/how-joe-biden-u-s-...   \n",
       "7  https://plana.earth/academy/how-joe-biden-u-s-...   \n",
       "8  https://plana.earth/academy/how-joe-biden-u-s-...   \n",
       "9  https://plana.earth/academy/how-joe-biden-u-s-...   \n",
       "\n",
       "                                               title  published  \\\n",
       "0    How sustainable is your office Christmas party? 2020-12-18   \n",
       "1    How sustainable is your office Christmas party? 2020-12-18   \n",
       "2    How sustainable is your office Christmas party? 2020-12-18   \n",
       "3    How sustainable is your office Christmas party? 2020-12-18   \n",
       "4    How sustainable is your office Christmas party? 2020-12-18   \n",
       "5  How will Biden and the US rejoin the Paris Agr... 2020-12-15   \n",
       "6  How will Biden and the US rejoin the Paris Agr... 2020-12-15   \n",
       "7  How will Biden and the US rejoin the Paris Agr... 2020-12-15   \n",
       "8  How will Biden and the US rejoin the Paris Agr... 2020-12-15   \n",
       "9  How will Biden and the US rejoin the Paris Agr... 2020-12-15   \n",
       "\n",
       "                                             content tag  human_one  \\\n",
       "0  Christmas is just around the corner! Unfortuna...   p   0.129480   \n",
       "1  Before we start, here are a few statistics on ...   p   0.170685   \n",
       "2    It is time for the office Christmas Party Quiz!  h2   0.201742   \n",
       "3  Find out how sustainable your Christmas Party ...   p   0.193324   \n",
       "4                  May the Merry Force be with you!   h2   0.269240   \n",
       "5  It is the fifth anniversary of the Paris Clima...   p   0.124986   \n",
       "6  The US President-Elect Joe Biden vows to rejoi...   p   0.122715   \n",
       "7  This follows the United States’ withdrawal fro...   p   0.086032   \n",
       "8  Today, the Trump Administration officially lef...   p   0.148504   \n",
       "9  Today, the Trump Administration officially lef...   p   0.153953   \n",
       "\n",
       "   seem_focu  less_decid  even_long  plan_sustain  cultur_nativ  bee_music  \\\n",
       "0   0.064434    0.003364   0.027903      0.233645      0.017146   0.038770   \n",
       "1   0.015211    0.003975   0.033012      0.046098      0.020283   0.015379   \n",
       "2   0.021895    0.005719   0.047522      0.065292      0.029197   0.022136   \n",
       "3   0.020962    0.005484   0.045488      0.104568      0.027951   0.021197   \n",
       "4   0.024003    0.006269   0.052097      0.071576      0.032007   0.024266   \n",
       "5   0.013552    0.003545   0.029408      0.067596      0.018071   0.013704   \n",
       "6   0.013347    0.003475   0.028964      0.039784      0.017789   0.013480   \n",
       "7   0.022989    0.146809   0.031940      0.022954      0.025552   0.007729   \n",
       "8   0.016179    0.037333   0.035093      0.048196      0.021547   0.016324   \n",
       "9   0.016729    0.038197   0.036291      0.049860      0.022291   0.016897   \n",
       "\n",
       "   tree_natur  water_credit  year_understand  \n",
       "0    0.240459      0.014376         0.230422  \n",
       "1    0.255159      0.017005         0.423192  \n",
       "2    0.293736      0.024476         0.288286  \n",
       "3    0.350031      0.023436         0.207561  \n",
       "4    0.352234      0.026832         0.141477  \n",
       "5    0.209292      0.015151         0.504694  \n",
       "6    0.176903      0.014908         0.568635  \n",
       "7    0.154619      0.008546         0.492831  \n",
       "8    0.217574      0.018054         0.441196  \n",
       "9    0.226360      0.018685         0.420737  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_academy = lda_results_to_df(academy_corpus, academy_id2word, academy_df)\n",
    "full_academy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../04_Data/lda_separated_posts.pkl', 'wb') as fa:\n",
    "    pickle.dump(full_academy, fa, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
